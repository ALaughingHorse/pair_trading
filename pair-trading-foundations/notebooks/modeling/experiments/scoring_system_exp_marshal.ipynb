{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4811023e-d8ef-4c27-ab22-300d9add312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "def score_pair(vec, past_successes, weights=[]):\n",
    "    \"\"\"\n",
    "    vec: a 1d numpy array \n",
    "    past_succcesses: a N-d Numpy array\n",
    "    \"\"\"\n",
    "    # calculate how similar is the current pair's historical patterns to past successes\n",
    "    scores = [cos_sim(vec, x) for x in past_successes]\n",
    "    if len(weights) > 0:\n",
    "        weights_sum = np.sum(weights)\n",
    "        # re-scaling\n",
    "        weights = np.array([x/weights_sum for x in weights])\n",
    "        scores = scores*weights\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa54df-d7dd-4025-bf47-5fdd77da0c09",
   "metadata": {},
   "source": [
    "# Load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7560e426-1d27-462d-bca3-7e0d16414e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178030, 38)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../Data/Training/exploration_190pairs_300_20.csv')\n",
    "# df['pnls'] = df['pnls']*100.0\n",
    "df = df.sort_values('Date', ascending=True)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.both_legs_profited = df.both_legs_profited=='True'\n",
    "df = df.dropna(subset=['pnls'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abeb702-2b90-410e-ad60-2a9795be2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Ticker_P1', 'Close_P1', 'Ticker_P2', 'Close_P2', 'High_P1',\n",
       "       'High_P2', 'Low_P1', 'Low_P2', 'Volume_P1', 'Volume_P2', 'abs_spread',\n",
       "       'same_sector_flag', 'same_sub_industry_flag', 'abs_spread_mean',\n",
       "       'abs_spread_std', 'abs_spread_mean_l20', 'abs_spread_std_l20',\n",
       "       'spread_normed', 'abs_spread_normed_max', 'abs_spread_normed_90th',\n",
       "       'abs_spread_normed_75th', 'abs_spread_normed_median',\n",
       "       'abs_spread_normed_l7_avg', 'abs_spread_normed_l14_avg', 'cos_sim',\n",
       "       'corr_coef_l5', 'corr_coef_l10', 'corr_coef_l15', 'corr_coef_l20',\n",
       "       'corr_coef_l40', 'corr_coef_l60', 'pnls', 'num_entries',\n",
       "       'days_till_first_entry', 'both_legs_profited', 'SPY_return',\n",
       "       'successful_pair_trading'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0513fb-3175-4a08-83cb-217dff231ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178030, 39)\n",
      "(178030, 39)\n"
     ]
    }
   ],
   "source": [
    "# features_names = ['cos_sim', 'corr_coef_l5','corr_coef_l10', 'corr_coef_l15', \n",
    "#                    'corr_coef_l20', 'corr_coef_l40', 'corr_coef_l60',\n",
    "#                   'same_sector_flag', 'same_sub_industry_flag',\n",
    "#                    'abs_spread_normed_max', 'abs_spread_normed_90th',\n",
    "#                    'abs_spread_normed_75th', 'abs_spread_normed_median',\n",
    "#                    'abs_spread_normed_l7_avg', 'abs_spread_normed_l14_avg']\n",
    "features_names = ['corr_coef_l5','corr_coef_l10', 'corr_coef_l15', \n",
    "                   'corr_coef_l20', 'corr_coef_l40', 'corr_coef_l60',\n",
    "                  'same_sector_flag', 'same_sub_industry_flag']\n",
    "\n",
    "label = 'both_legs_profited'\n",
    "# label = 'successful_pair_trading'\n",
    "print(df.shape)\n",
    "df = df.dropna(subset=features_names)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25596077-e615-413b-b8e8-5a2ffbfa2400",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "114c2826-3e92-4608-96eb-e1c5ed23f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data is the latest date\n",
    "test_data  = df[df['Date']=='2019-09-23'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1197c83-ca5c-4f82-b0ff-7e1596e770a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data is 20 trading days ago. For ease of compute just took anything more than a month back\n",
    "train_data = df[df['Date']<'2019-08-23'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e516410d-0023-4d02-8e80-71acdab77489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the success pair tradings from history\n",
    "all_successes = train_data[train_data[label]]\n",
    "\n",
    "# weights = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39cea738-c10c-470d-9c6b-d1dda565cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_successes[features_names]\n",
    "X_test = test_data[features_names]\n",
    "y_test = test_data[[label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54e2ce68-7004-4f30-989c-8fa681691feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "# scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d199aab-6897-451e-9cfa-3efb2860d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "pair_past_success_tb = all_successes[\n",
    "        (all_successes.Ticker_P1==test_data.Ticker_P1.values[i])&(all_successes.Ticker_P2==test_data.Ticker_P2.values[i])\n",
    "    ]\n",
    "pair_past_success_tb.shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafc3eb-b3ad-4b88-9f2d-9a7e5250bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_data.shape[0]):\n",
    "    pair_past_success_tb = all_successes[\n",
    "        \n",
    "    ]\n",
    "    if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96af7a-8ecf-4435-8afb-b0fa2fe380c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [score_pair(x, scaled_X_train) for x in scaled_X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ec10e-c1f1-4fd6-93c0-abce8f97a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c4e16-d98e-41e4-afd8-d4527e7747cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positives = sum(y_test[label])\n",
    "print(total_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c8463-cb94-4a64-a55c-3d4b0d966e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Highest scores\n",
    "\"\"\"\n",
    "pat1 = y_test.sort_values('scores',ascending=False).head(1)[label].mean()\n",
    "\n",
    "pat3 = y_test.sort_values('scores',ascending=False).head(3)[label].mean()\n",
    "\n",
    "pat5 = y_test.sort_values('scores',ascending=False).head(5)[label].mean()\n",
    "print(f'Number of positive pairs: {total_positives}')\n",
    "print(f'Pct of positive pairs among all possible pairs: {np.mean(y_test[label])}')\n",
    "print(f'Precision @ 1: {pat1}')\n",
    "print(f'Precision @ 3: {pat3}')\n",
    "print(f'Precision @ 5: {pat5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd59247-2324-4889-8612-12edafaead2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lowest scores for sanity check\n",
    "\"\"\"\n",
    "pat1 = y_test.sort_values('scores',ascending=True).head(1)[label].mean()\n",
    "pat3 = y_test.sort_values('scores',ascending=True).head(3)[label].mean()\n",
    "pat5 = y_test.sort_values('scores',ascending=True).head(5)[label].mean()\n",
    "print(f'Precision @ 1: {pat1}')\n",
    "print(f'Precision @ 3: {pat3}')\n",
    "print(f'Precision @ 5: {pat5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bc900-b782-4262-a0e6-b0fe4f9780fa",
   "metadata": {},
   "source": [
    "# Pick test dates and score the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b29eaf-f008-47cf-87ec-c768bb3b3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_dates = 10\n",
    "all_test_dates = df['Date'].drop_duplicates().sort_values(ascending=True).values[30:]\n",
    "test_dates = random.sample(list(all_test_dates), n_test_dates)\n",
    "\n",
    "# test on the latest 60 days\n",
    "test_dates = df['Date'].drop_duplicates().sort_values(ascending=False).head(60).values\n",
    "train_test_date_pairs = [\n",
    "    ((datetime.strptime(x, '%Y-%m-%d') - timedelta(days=30)).strftime('%Y-%m-%d'),x) for x in test_dates\n",
    "]\n",
    "train_test_date_pairs\n",
    "\"\"\"\n",
    "First value of the train_test_date_pairs tuple is the threshold on which we collect training data.\n",
    "The second value is the date\n",
    "\"\"\"\n",
    "\n",
    "target_date = [x[1] for x in train_test_date_pairs]\n",
    "all_pat1 = []\n",
    "all_pat3 = []\n",
    "all_pat5 = []\n",
    "\n",
    "for tup in train_test_date_pairs:\n",
    "    # test data is the latest date\n",
    "    test_data  = df[df['Date']==tup[1]]\n",
    "    # train data is 20 trading days ago. For ease of compute just took anything more than a month back\n",
    "    train_data = df[df['Date']<tup[0]] \n",
    "    # get all the success pair tradings from history\n",
    "    all_successes = train_data[train_data[label]]\n",
    "\n",
    "    # Get the features\n",
    "    X_train = all_successes[features_names]\n",
    "    X_test = test_data[features_names]\n",
    "    y_test = test_data[[label]]\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    scaled_X_train = scaler.transform(X_train)\n",
    "    scaled_X_test = scaler.transform(X_test)\n",
    "    \n",
    "    scores = [score_pair(x, scaled_X_train) for x in scaled_X_test]\n",
    "\n",
    "    y_test['scores'] = scores\n",
    "    pat1 = y_test.sort_values('scores',ascending=False).head(1)[label].mean()\n",
    "    pat3 = y_test.sort_values('scores',ascending=False).head(3)[label].mean()\n",
    "    pat5 = y_test.sort_values('scores',ascending=False).head(5)[label].mean()\n",
    "    all_pat1.append(pat1)\n",
    "    all_pat3.append(pat3)\n",
    "    all_pat5.append(pat5)\n",
    "\n",
    "np.mean(all_pat1)\n",
    "np.mean(all_pat3)\n",
    "np.mean(all_pat5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
